{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90279,"databundleVersionId":10477255,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install -U albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:38:05.632074Z","iopub.execute_input":"2024-12-15T02:38:05.632396Z","iopub.status.idle":"2024-12-15T02:38:24.462142Z","shell.execute_reply.started":"2024-12-15T02:38:05.632359Z","shell.execute_reply":"2024-12-15T02:38:24.461089Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.49 ultralytics-thop-2.0.13\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.21)\nCollecting albumentations\n  Downloading albumentations-1.4.22-py3-none-any.whl.metadata (33 kB)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.10.1)\nCollecting albucore==0.0.21 (from albumentations)\n  Downloading albucore-0.0.21-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /opt/conda/lib/python3.10/site-packages (from albucore==0.0.21->albumentations) (3.10.10)\nRequirement already satisfied: simsimd>=5.9.2 in /opt/conda/lib/python3.10/site-packages (from albucore==0.0.21->albumentations) (6.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\nDownloading albumentations-1.4.22-py3-none-any.whl (258 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading albucore-0.0.21-py3-none-any.whl (12 kB)\nInstalling collected packages: albucore, albumentations\n  Attempting uninstall: albucore\n    Found existing installation: albucore 0.0.20\n    Uninstalling albucore-0.0.20:\n      Successfully uninstalled albucore-0.0.20\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 1.4.21\n    Uninstalling albumentations-1.4.21:\n      Successfully uninstalled albumentations-1.4.21\nSuccessfully installed albucore-0.0.21 albumentations-1.4.22\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"\nimport os\nimport shutil\nimport pandas as pd\n\n# Define paths\ncsv_file_path = '/kaggle/input/datathon-ai-qualification-round/train_data.csv'\nsource_folder = '/kaggle/input/datathon-ai-qualification-round/train/train'\ndestination_base =  '/kaggle/working/Sehirler/train/train'\n\n# Load CSV data\ntrain_data = pd.read_csv(csv_file_path)\n\n# Create city directories in the destination folder\nfor city in train_data['city'].unique():\n    city_folder = os.path.join(destination_base, city)\n    os.makedirs(city_folder, exist_ok=True)\n\n# Move files to their respective city folders\nfor index, row in train_data.iterrows():\n    filename = row['filename']\n    city = row['city']\n    \n    source_file = os.path.join(source_folder, filename)\n    destination_file = os.path.join(destination_base, city, filename)\n\n    # Check if the source file exists\n    if os.path.exists(source_file):\n        shutil.copy(source_file, destination_file)\n    else:\n        print(f\"Warning: {source_file} does not exist.\")\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\n# CSV dosyasını yükle\ncsv_path = \"/kaggle/input/datathon-ai-qualification-round/train_data.csv\"  # CSV dosyanızın tam yolu\nimage_folder = \"/kaggle/input/datathon-ai-qualification-round/train/train\"  # Fotoğrafların bulunduğu klasör\noutput_folder = \"/kaggle/working/Sehirler\"  # Çıktı klasörü\n\n# CSV'yi oku\ndf = pd.read_csv(csv_path)\n\n# Şehir klasörlerini oluştur ve fotoğrafları taşı\nfor _, row in df.iterrows():\n    city = row['city']\n    filename = row['filename']\n    \n    # Şehir klasörünün yolunu oluştur\n    city_folder = os.path.join(output_folder, city)\n    os.makedirs(city_folder, exist_ok=True)\n    \n    # Fotoğrafın mevcut ve hedef yolunu oluştur\n    source_path = os.path.join(image_folder, filename)\n    target_path = os.path.join(city_folder, filename)\n    \n    # Fotoğrafı taşı\n    if os.path.exists(source_path):\n        shutil.copy(source_path, target_path)\n    else:\n        print(f\"{filename} bulunamadı.\")\n\nprint(\"Fotoğraflar başarıyla taşındı.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:38:24.463989Z","iopub.execute_input":"2024-12-15T02:38:24.464279Z","iopub.status.idle":"2024-12-15T02:39:07.813119Z","shell.execute_reply.started":"2024-12-15T02:38:24.464246Z","shell.execute_reply":"2024-12-15T02:39:07.812242Z"}},"outputs":[{"name":"stdout","text":"Fotoğraflar başarıyla taşındı.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Şehirleri sınıflara çevir\ncity_to_class = {city: idx for idx, city in enumerate(df['city'].unique())}\n\n# YOLO formatında etiket dosyalarını oluştur\nfor _, row in df.iterrows():\n    city = row['city']\n    filename = row['filename']\n    image_path = os.path.join(output_folder, city, filename)\n    \n    if os.path.exists(image_path):\n        # Etiket dosyasının yolunu oluştur\n        label_path = image_path.replace(\".jpg\", \".txt\")\n        class_id = city_to_class[city]\n        \n        # Tüm görüntüyü kapsayan bir \"box\" kullanıyoruz\n        with open(label_path, \"w\") as f:\n            f.write(f\"{class_id} 0.5 0.5 1.0 1.0\\n\")  # x_center, y_center, width, height\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:39:07.814391Z","iopub.execute_input":"2024-12-15T02:39:07.815089Z","iopub.status.idle":"2024-12-15T02:39:08.741278Z","shell.execute_reply.started":"2024-12-15T02:39:07.815048Z","shell.execute_reply":"2024-12-15T02:39:08.740596Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"city_to_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:39:08.742699Z","iopub.execute_input":"2024-12-15T02:39:08.742971Z","iopub.status.idle":"2024-12-15T02:39:08.749097Z","shell.execute_reply.started":"2024-12-15T02:39:08.742946Z","shell.execute_reply":"2024-12-15T02:39:08.748256Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Istanbul': 0, 'Ankara': 1, 'Izmir': 2}"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## BURAYA KADAR HER ŞEY AYNI","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# Eğitim, doğrulama ve test setleri için oranlar\ntrain_ratio = 0.7\nval_ratio = 0.2\n\n# Tüm verileri shuffle'la\nimages = [os.path.join(root, file) \n          for root, _, files in os.walk(output_folder) for file in files if file.endswith(\".jpg\")]\nrandom.shuffle(images)\n\n# Verileri böl\ntrain_split = int(len(images) * train_ratio)\nval_split = int(len(images) * (train_ratio + val_ratio))\n\ntrain_files = images[:train_split]\nval_files = images[train_split:val_split]\ntest_files = images[val_split:]\n\n# Eğitim, doğrulama ve test klasörlerini oluştur\ndataset_folder = \"/kaggle/working/SehirlerDataset\"\nos.makedirs(os.path.join(dataset_folder, \"train\"), exist_ok=True)\nos.makedirs(os.path.join(dataset_folder, \"val\"), exist_ok=True)\nos.makedirs(os.path.join(dataset_folder, \"test\"), exist_ok=True)\n\n# Dosyaları ve ilgili .txt dosyalarını taşı\nfor file_set, folder in zip([train_files, val_files, test_files], [\"train\", \"val\", \"test\"]):\n    for file in file_set:\n        # .jpg dosyasını taşı\n        target_image_path = os.path.join(dataset_folder, folder, os.path.basename(file))\n        shutil.move(file, target_image_path)\n\n        # İlgili .txt dosyasını kontrol et ve taşı\n        label_file = file.replace(\".jpg\", \".txt\")\n        if os.path.exists(label_file):\n            target_label_path = os.path.join(dataset_folder, folder, os.path.basename(label_file))\n            shutil.move(label_file, target_label_path)\n\nprint(\"Resimler ve etiketler başarıyla bölündü ve taşındı.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\n\n# YAML dosyası için veri\ndata_yaml = {\n    'train': '/kaggle/working/SehirlerDataset/train',\n    'val': '/kaggle/working/SehirlerDataset/val',\n    'nc': 3,\n    'names': ['Istanbul', 'Ankara', 'Izmir']\n}\n\n# YAML dosyasını oluştur\nyaml_path = \"/kaggle/working/SehirlerDataset/data.yaml\"\nwith open(yaml_path, 'w') as yaml_file:\n    yaml.dump(data_yaml, yaml_file, default_flow_style=False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef list_unique_extensions(folder_path):\n    \"\"\"\n    Belirtilen bir klasördeki eşsiz dosya uzantılarını listeleyen fonksiyon.\n\n    Args:\n        folder_path (str): Klasör yolu.\n\n    Returns:\n        set: Bulunan benzersiz uzantıları içeren set.\n    \"\"\"\n    unique_extensions = set()\n    \n    # Klasördeki dosyaları gez\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            _, ext = os.path.splitext(file)\n            if ext:  # Eğer dosya uzantısı varsa\n                unique_extensions.add(ext)\n\n    return unique_extensions\n\n# Kullanım örneği\nfolder_path = \"/kaggle/working/SehirlerDatasetSplit\"  # Klasör yolunu düzenleyin\n\nextensions = list_unique_extensions(folder_path)\n\nif extensions:\n    print(\"Klasördeki benzersiz dosya uzantıları:\")\n    for ext in extensions:\n        print(ext)\nelse:\n    print(\"Klasörde herhangi bir dosya uzantısı bulunamadı.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T17:30:11.144651Z","iopub.execute_input":"2024-12-13T17:30:11.144977Z","iopub.status.idle":"2024-12-13T17:30:11.177380Z","shell.execute_reply.started":"2024-12-13T17:30:11.144947Z","shell.execute_reply":"2024-12-13T17:30:11.176657Z"}},"outputs":[{"name":"stdout","text":"Klasördeki benzersiz dosya uzantıları:\n.yaml\n.txt\n.jpg\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a pretrained model\nmodel = YOLO(\"yolo11n.pt\")\n\n# Train the model on your custom dataset\nmodel.train(data=\"/kaggle/working/SehirlerDataset/data.yaml\", epochs=100, imgsz=640, device=[0, 1], batch=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# Eğitim ve doğrulama setleri için oranlar\ntrain_ratio = 0.94  # Eğitim oranı (%80)\nval_ratio = 0.06    # Doğrulama oranı (%20)\n\n# Veri seti klasörleri\noutput_folder = \"/kaggle/working/Sehirler\"  # Ana klasör (Ankara, Izmir, Istanbul)\ndataset_folder = \"/kaggle/working/SehirlerDatasetSplit\"  # Bölünecek klasör\n\n# Eğitim ve doğrulama klasörlerini oluştur\nos.makedirs(os.path.join(dataset_folder, \"train\"), exist_ok=True)\nos.makedirs(os.path.join(dataset_folder, \"val\"), exist_ok=True)\n\n# Alt klasörleri dolaş\nfor class_name in os.listdir(output_folder):\n    class_path = os.path.join(output_folder, class_name)\n    if not os.path.isdir(class_path):\n        continue  # Sadece klasörlere odaklan\n\n    # Sınıfa ait tüm resim dosyalarını al\n    images = [os.path.join(class_path, file) for file in os.listdir(class_path) if file.endswith(\".jpg\")]\n    random.shuffle(images)  # Rastgele karıştır\n\n    # Eğitim ve doğrulama setlerini ayır\n    train_split = int(len(images) * train_ratio)\n    train_files = images[:train_split]\n    val_files = images[train_split:]\n\n    # Eğitim ve doğrulama setlerine taşı\n    for file_set, folder in zip([train_files, val_files], [\"train\", \"val\"]):\n        target_folder = os.path.join(dataset_folder, folder)  # Klasör isimlerini düz tut\n        for file in file_set:\n            # .jpg dosyasını taşı\n            target_image_path = os.path.join(target_folder, os.path.basename(file))\n            shutil.move(file, target_image_path)\n\n            # İlgili .txt dosyasını kontrol et ve taşı\n            label_file = file.replace(\".jpg\", \".txt\")\n            if os.path.exists(label_file):\n                target_label_path = os.path.join(target_folder, os.path.basename(label_file))\n                shutil.move(label_file, target_label_path)\n\nprint(\"Resimler ve etiketler başarıyla eğitim ve doğrulama setlerine bölündü ve taşındı.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:39:08.750189Z","iopub.execute_input":"2024-12-15T02:39:08.750439Z","iopub.status.idle":"2024-12-15T02:39:09.198041Z","shell.execute_reply.started":"2024-12-15T02:39:08.750416Z","shell.execute_reply":"2024-12-15T02:39:09.197190Z"}},"outputs":[{"name":"stdout","text":"Resimler ve etiketler başarıyla eğitim ve doğrulama setlerine bölündü ve taşındı.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import yaml\n\n# YAML dosyası için veri\ndata_yaml = {\n    'train': '/kaggle/working/SehirlerDatasetSplit/train',\n    'val': '/kaggle/working/SehirlerDatasetSplit/val',\n    'nc': 3,\n    'names': ['Istanbul', 'Ankara', 'Izmir']\n}\n\n# YAML dosyasını oluştur\nyaml_path = \"/kaggle/working/SehirlerDatasetSplit/data.yaml\"\nwith open(yaml_path, 'w') as yaml_file:\n    yaml.dump(data_yaml, yaml_file, default_flow_style=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T02:39:09.198999Z","iopub.execute_input":"2024-12-15T02:39:09.199263Z","iopub.status.idle":"2024-12-15T02:39:09.221621Z","shell.execute_reply.started":"2024-12-15T02:39:09.199238Z","shell.execute_reply":"2024-12-15T02:39:09.221021Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a pretrained model\nmodel = YOLO(\"yolo11m.pt\")\n\n# Train the model on your custom dataset\nmodel.train(data=\"/kaggle/working/SehirlerDatasetSplit/data.yaml\", epochs=100, imgsz=640, device=[0, 1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/SehirlerDatasetSplit/train -1 | wc -l","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SADECE LİNEAR DÜZ CLIP","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:18:26.089362Z","iopub.execute_input":"2024-12-16T02:18:26.090175Z","iopub.status.idle":"2024-12-16T02:18:40.465045Z","shell.execute_reply.started":"2024-12-16T02:18:26.090134Z","shell.execute_reply":"2024-12-16T02:18:40.464136Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-e09sjqyg\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-e09sjqyg\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=dec83c865ffd260090483557c4937614c4350c22ceb5cf0676bf43c1b3e560c5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-jw8b1h34/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nimport clip\n# Eğer openclip kullanacaksanız:\n# !pip install open_clip_torch\n# import open_clip\n\n# MODEL YÜKLEME (OpenAI CLIP)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-L/14@336px\", device=device)  # ya da daha büyük bir model\nmodel.eval()\n\n# VERİYİ YÜKLE\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")  # filename, city kolonları var\nimage_paths = df['filename'].apply(lambda x: f\"/kaggle/input/datathon-ai-qualification-round/train/train/{x}\")\ncities = df['city'].unique().tolist()\n\n# TEXT PROMPTLARINI HAZIRLA\ntext_prompts = [f\"A photo of Türkiye in {city}.\" for city in cities]\n\n# TEXT EMBEDDINGS\nwith torch.no_grad():\n    text_tokens = clip.tokenize(text_prompts).to(device)\n    text_features = model.encode_text(text_tokens)\n    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n\n# ZERO-SHOT SINIFLANDIRMA TESTİ\ncorrect = 0\nfor idx, row in tqdm(df.iterrows(), total=len(df)):\n    img_path = row['filename']\n    label = row['city']\n    image = preprocess(Image.open(f\"/kaggle/input/datathon-ai-qualification-round/train/train/{img_path}\")).unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        image_features = model.encode_image(image)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n    \n    similarity = (image_features @ text_features.T).squeeze(0)\n    # En yüksek skor hangi şehir ise onu tahmin et\n    pred_idx = similarity.argmax().item()\n    pred_city = cities[pred_idx]\n\n    if pred_city == label:\n        correct += 1\n\naccuracy = correct / len(df)\nprint(\"Zero-Shot Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:54:01.046463Z","iopub.execute_input":"2024-12-14T15:54:01.046796Z","iopub.status.idle":"2024-12-14T15:59:00.836594Z","shell.execute_reply.started":"2024-12-14T15:54:01.046765Z","shell.execute_reply":"2024-12-14T15:59:00.835697Z"}},"outputs":[{"name":"stderr","text":"100%|████████████████████████████████████████| 891M/891M [00:05<00:00, 157MiB/s]\n100%|██████████| 7000/7000 [04:40<00:00, 24.93it/s]","output_type":"stream"},{"name":"stdout","text":"Zero-Shot Accuracy: 0.7591428571428571\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm\nimport clip\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\n# -----------------\n# Hyperparametreler\n# -----------------\nbatch_size = 32\nlearning_rate = 1e-3\nepochs = 500\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---------\n# MODEL YÜKLE\n# ---------\nmodel, preprocess = clip.load(\"ViT-L/14\", device=device)\nmodel.eval()\n\n# -----------------\n# DATASET HAZIRLAMA\n# -----------------\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")  # filename, city kolonları var\nimage_paths = df['filename'].apply(lambda x: f\"/kaggle/input/datathon-ai-qualification-round/train/train/{x}\").values\ncities = df['city'].unique().tolist()\ncity_to_idx = {c: i for i, c in enumerate(cities)}\nlabels = df['city'].apply(lambda x: city_to_idx[x]).values\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\ndataset = ImageDataset(image_paths, labels, preprocess)\n\n# Basitçe tüm verileri tek seferde embedding'e çevirebiliriz (veri küçükse).\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\nall_image_features = []\nall_labels = []\n\nwith torch.no_grad():\n    for imgs, labs in tqdm(dataloader):\n        imgs = imgs.to(device)\n        image_features = model.encode_image(imgs)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        all_image_features.append(image_features.cpu())\n        all_labels.append(labs)\n\nall_image_features = torch.cat(all_image_features, dim=0)\nall_labels = torch.cat(all_labels, dim=0)\n\n# Veriyi train/val/test olarak ayırın.\n# Burada basitçe %80-%20 bölelim örnek olması için.\nnum_samples = len(all_image_features)\ntrain_size = int(0.6 * num_samples)\nval_size = num_samples - train_size\n\ntrain_features = all_image_features[:train_size]\ntrain_labels = all_labels[:train_size]\n\nval_features = all_image_features[train_size:]\nval_labels = all_labels[train_size:]\n\n# ------------------------\n# LINEAR PROBING MODELİ\n# ------------------------\n# CLIP feature boyutunu öğrenelim\nfeature_dim = train_features.shape[1]\nnum_classes = len(cities)\n\nlinear_classifier = nn.Linear(feature_dim, num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(linear_classifier.parameters(), lr=learning_rate)\n\n# ------------------------\n# EĞİTİM DÖNGÜSÜ\n# ------------------------\nfor epoch in range(epochs):\n    linear_classifier.train()\n    # Veriyi random karıştırmak için tekrar dataloader yapabiliriz ama burada direkt batch loop yapalım.\n    permutation = torch.randperm(train_size)\n    train_features_shuf = train_features[permutation]\n    train_labels_shuf = train_labels[permutation]\n\n    for i in range(0, train_size, batch_size):\n        batch_feats = train_features_shuf[i:i+batch_size].to(device)\n        batch_labs = train_labels_shuf[i:i+batch_size].to(device)\n\n        optimizer.zero_grad()\n        outputs = linear_classifier(batch_feats.float())\n        loss = criterion(outputs, batch_labs)\n        loss.backward()\n        optimizer.step()\n\n    # Validation\n    linear_classifier.eval()\n    with torch.no_grad():\n        val_outputs = linear_classifier(val_features.float().to(device))\n        val_pred = val_outputs.argmax(dim=1).cpu()  # Tahminler CPU'ya alınır\n        # val_labels zaten CPU'da ise direkt kullanabilirsiniz, değilse val_labels.cpu() yapın\n        f1 = f1_score(val_labels.cpu(), val_pred, average='macro')\n    \n    print(f\"Validation Macro F1: {f1:.4f}\")\n\n# Eğitim bittiğinde en iyi val acc elde ettiğiniz modeli kaydedebilirsiniz.\n# test setiniz varsa onu da benzer şekilde değerlendirebilirsiniz.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm\nimport clip\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom sklearn.metrics import f1_score\nimport os\n\n# ---------------\n# Hyperparametreler\n# ---------------\nbatch_size = 32\nlearning_rate = 1e-3\nepochs = 500\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---------\n# MODEL YÜKLEME (CLIP)\n# ---------\nmodel, preprocess = clip.load(\"ViT-L/14\", device=device)\nmodel.eval()\n\n# -----------------\n# TRAIN DATA YÜKLEME\n# -----------------\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")  # filename, city kolonları var\nimage_paths = df['filename'].apply(lambda x: f\"/kaggle/input/datathon-ai-qualification-round/train/train/{x}\").values\ncities = df['city'].unique().tolist()\ncity_to_idx = {c: i for i, c in enumerate(cities)}\nlabels = df['city'].apply(lambda x: city_to_idx[x]).values\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\ndataset = ImageDataset(image_paths, labels, preprocess)\n\n# Tüm verilerden embedding çıkar\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\nall_image_features = []\nall_labels = []\n\nwith torch.no_grad():\n    for imgs, labs in tqdm(dataloader):\n        imgs = imgs.to(device)\n        image_features = model.encode_image(imgs)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        all_image_features.append(image_features.cpu())\n        all_labels.append(labs)\n\nall_image_features = torch.cat(all_image_features, dim=0)\nall_labels = torch.cat(all_labels, dim=0)\n\n# Veriyi train/val olarak ayıralım (ör: %80-%20)\nnum_samples = len(all_image_features)\ntrain_size = int(0.8 * num_samples)\nval_size = num_samples - train_size\n\ntrain_features = all_image_features[:train_size]\ntrain_labels = all_labels[:train_size]\n\nval_features = all_image_features[train_size:]\nval_labels = all_labels[train_size:]\n\nfeature_dim = train_features.shape[1]\nnum_classes = len(cities)\n\nlinear_classifier = nn.Linear(feature_dim, num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(linear_classifier.parameters(), lr=learning_rate)\n\nbest_f1 = 0.0\nmodel_path = \"/kaggle/working/linear_classifier_best.pt\"\n\nfor epoch in range(epochs):\n    linear_classifier.train()\n    permutation = torch.randperm(train_size)\n    train_features_shuf = train_features[permutation]\n    train_labels_shuf = train_labels[permutation]\n\n    # Mini-batch eğitim\n    for i in range(0, train_size, batch_size):\n        batch_feats = train_features_shuf[i:i+batch_size].to(device)\n        batch_labs = train_labels_shuf[i:i+batch_size].to(device)\n\n        optimizer.zero_grad()\n        outputs = linear_classifier(batch_feats.float())\n        loss = criterion(outputs, batch_labs)\n        loss.backward()\n        optimizer.step()\n\n    # Validation aşaması\n    linear_classifier.eval()\n    with torch.no_grad():\n        val_outputs = linear_classifier(val_features.float().to(device))\n        val_pred = val_outputs.argmax(dim=1).cpu()\n        f1 = f1_score(val_labels.cpu(), val_pred, average='macro')\n    \n    print(f\"Epoch {epoch+1}/{epochs} - Validation Macro F1: {f1:.4f}\")\n\n    # En iyi model kontrolü\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(linear_classifier.state_dict(), model_path)\n        print(\"Best model saved with F1:\", best_f1)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2024-12-13T23:50:21.468004Z","shell.execute_reply.started":"2024-12-13T23:46:10.111885Z","shell.execute_reply":"2024-12-13T23:50:21.467115Z"}},"outputs":[{"name":"stdout","text":"Epoch 473/500 - Validation Macro F1: 0.9256\nEpoch 474/500 - Validation Macro F1: 0.9249\nEpoch 475/500 - Validation Macro F1: 0.9264\nEpoch 476/500 - Validation Macro F1: 0.9249\nEpoch 477/500 - Validation Macro F1: 0.9249\nEpoch 478/500 - Validation Macro F1: 0.9257\nEpoch 479/500 - Validation Macro F1: 0.9257\nEpoch 480/500 - Validation Macro F1: 0.9257\nEpoch 481/500 - Validation Macro F1: 0.9278\nEpoch 482/500 - Validation Macro F1: 0.9257\nEpoch 483/500 - Validation Macro F1: 0.9249\nEpoch 484/500 - Validation Macro F1: 0.9249\nEpoch 485/500 - Validation Macro F1: 0.9264\nEpoch 486/500 - Validation Macro F1: 0.9249\nEpoch 487/500 - Validation Macro F1: 0.9250\nEpoch 488/500 - Validation Macro F1: 0.9249\nEpoch 489/500 - Validation Macro F1: 0.9250\nEpoch 490/500 - Validation Macro F1: 0.9271\nEpoch 491/500 - Validation Macro F1: 0.9250\nEpoch 492/500 - Validation Macro F1: 0.9264\nEpoch 493/500 - Validation Macro F1: 0.9249\nEpoch 494/500 - Validation Macro F1: 0.9264\nEpoch 495/500 - Validation Macro F1: 0.9264\nEpoch 496/500 - Validation Macro F1: 0.9264\nEpoch 497/500 - Validation Macro F1: 0.9257\nEpoch 498/500 - Validation Macro F1: 0.9257\nEpoch 499/500 - Validation Macro F1: 0.9249\nEpoch 500/500 - Validation Macro F1: 0.9264\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_23/1277279265.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  linear_classifier.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=768, out_features=3, bias=True)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# En iyi modeli yükleyelim\nlinear_classifier.load_state_dict(torch.load(model_path))\nlinear_classifier.eval()\n\n# ---------------\n# TEST VERİSİ İŞLEME\n# ---------------\ntest_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/test.csv\")  # Sadece filename var\ntest_filenames = test_df['filename'].values\n\n# Test verisi için embedding çıkar\ntest_images = []\nwith torch.no_grad():\n    for fname in tqdm(test_filenames):\n        img_path = f\"/kaggle/input/datathon-ai-qualification-round/test/test/{fname}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        img_tensor = preprocess(image).unsqueeze(0).to(device)\n        \n        image_features = model.encode_image(img_tensor)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        test_images.append(image_features.cpu())\n\ntest_images = torch.cat(test_images, dim=0)\n\nwith torch.no_grad():\n    test_outputs = linear_classifier(test_images.float().to(device))\n    test_pred_idx = test_outputs.argmax(dim=1).cpu().numpy()\n    test_pred_cities = [cities[idx] for idx in test_pred_idx]\n\n# Sonuçları submit.csv'ye yaz\nsubmission_df = test_df.copy()\nsubmission_df[\"city\"] = test_pred_cities\nsubmission_df.to_csv(\"/kaggle/working/submit.csv\", index=False)\n\nprint(\"submit.csv dosyası oluşturuldu. En iyi modelle test tahmini tamamlandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T23:50:39.733923Z","iopub.execute_input":"2024-12-13T23:50:39.734314Z","iopub.status.idle":"2024-12-13T23:51:31.253638Z","shell.execute_reply.started":"2024-12-13T23:50:39.734277Z","shell.execute_reply":"2024-12-13T23:51:31.252719Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/1506039412.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  linear_classifier.load_state_dict(torch.load(model_path))\n100%|██████████| 2000/2000 [00:51<00:00, 38.84it/s]","output_type":"stream"},{"name":"stdout","text":"submit.csv dosyası oluşturuldu. En iyi modelle test tahmini tamamlandı.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OPENAI CLIP LINEAR MLP VB HİPERPARAMETRE DEĞİŞTİREN","metadata":{}},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nimport clip\n\n############################\n# Data Loading and Dataset #\n############################\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\n\n###########################\n# Classifier Architectures#\n###########################\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\n###########################\n# Training/Evaluation Code#\n###########################\n\ndef extract_embeddings(model, preprocess, image_paths, labels, batch_size=32, device=\"cuda\"):\n    dataset = ImageDataset(image_paths, labels, preprocess)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    all_image_features = []\n    all_labels = []\n\n    model.eval()\n    with torch.no_grad():\n        for imgs, labs in tqdm(dataloader):\n            imgs = imgs.to(device)\n            image_features = model.encode_image(imgs)\n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n            all_image_features.append(image_features.cpu())\n            all_labels.append(labs)\n\n    all_image_features = torch.cat(all_image_features, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n    return all_image_features, all_labels\n\n\ndef train_and_evaluate(model_name,\n                       train_df_path,\n                       train_img_dir,\n                       prompt_template=\"A photo of Türkiye in {}.\",\n                       classifier_type=\"linear\",  # \"linear\" or \"mlp\"\n                       lr=1e-3,\n                       optimizer_type=\"adam\",  # \"adam\", \"adamw\", \"sgd\"\n                       epochs=50,\n                       hidden_dim=512,\n                       weight_decay=0.0,\n                       early_stopping=False,\n                       patience=10,\n                       device=\"cuda\",\n                      just_name=\"zor\"):\n\n    # Load CLIP model\n    clip_model, preprocess = clip.load(model_name, device=device)\n    clip_model.eval()\n\n    # Load train data\n    df = pd.read_csv(train_df_path)\n    cities = df['city'].unique().tolist()\n    city_to_idx = {c: i for i, c in enumerate(cities)}\n    labels = df['city'].apply(lambda x: city_to_idx[x]).values\n    image_paths = df['filename'].apply(lambda x: f\"{train_img_dir}/{x}\").values\n\n    # Optionally change prompts if doing zero-shot or embedding text differently\n    # (For now we don't do prompt learning here, just a placeholder if needed)\n\n    # Extract embeddings\n    all_image_features, all_labels = extract_embeddings(clip_model, preprocess, image_paths, labels, device=device)\n\n    # Split train/val\n    num_samples = len(all_image_features)\n    train_size = int(0.9 * num_samples)\n    val_size = num_samples - train_size\n\n    train_features = all_image_features[:train_size]\n    train_labels = all_labels[:train_size]\n\n    val_features = all_image_features[train_size:]\n    val_labels = all_labels[train_size:]\n\n    feature_dim = train_features.shape[1]\n    num_classes = len(cities)\n\n    # Classifier\n    if classifier_type == \"linear\":\n        classifier = LinearClassifier(feature_dim, num_classes).to(device)\n    else:\n        classifier = MLPClassifier(feature_dim, hidden_dim, num_classes).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    if optimizer_type == \"adam\":\n        opt = optim.Adam(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n    elif optimizer_type == \"adamw\":\n        opt = optim.AdamW(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n    else:  # sgd\n        opt = optim.SGD(classifier.parameters(), lr=lr, momentum=0.98, weight_decay=weight_decay)\n\n    best_f1 = 0.0\n    no_improve_count = 0\n    model_path = f\"/kaggle/working/best_model_{just_name}.pt\"  # Kaydetmek istediğiniz dosya adı\n    \n    for epoch in range(epochs):\n        classifier.train()\n        permutation = torch.randperm(train_size)\n        train_features_shuf = train_features[permutation]\n        train_labels_shuf = train_labels[permutation]\n    \n        batch_size=32\n        for i in range(0, train_size, batch_size):\n            batch_feats = train_features_shuf[i:i+batch_size].to(device).float()\n            batch_labs = train_labels_shuf[i:i+batch_size].to(device)\n    \n            opt.zero_grad()\n            outputs = classifier(batch_feats)\n            loss = criterion(outputs, batch_labs)\n            loss.backward()\n            opt.step()\n    \n        # Validation\n        classifier.eval()\n        with torch.no_grad():\n            val_out = classifier(val_features.float().to(device))\n            val_pred = val_out.argmax(dim=1).cpu()\n            f1 = f1_score(val_labels, val_pred, average='macro')\n    \n       \n        \n        # En iyi modeli kaydet\n        if f1 > best_f1:\n            best_f1 = f1\n            no_improve_count = 0\n            torch.save(classifier.state_dict(), model_path)\n            print(f\"Best model saved with F1: {best_f1:.4f}\")\n        else:\n            no_improve_count += 1\n    \n        if early_stopping and no_improve_count >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    return best_f1, model_path, feature_dim, hidden_dim, num_classes\n\n\n###################\n# Example Runs     #\n###################\n\n# Örnek kullanımlar: Her seferinde sadece bir parametre değiştirip sonucu not edin.\n# Bu kodu birden çok kez farklı parametrelerle çalıştırarak deney yapabilirsiniz.\n\n\n\n# MLP deneyleri\nbest_f1, model_path, feature_dim, hidden_dim, num_classes = train_and_evaluate(\n    model_name=\"ViT-L/14@336px\",\n    train_df_path=\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\",\n    train_img_dir=\"/kaggle/input/datathon-ai-qualification-round/train/train\",\n    classifier_type=\"mlp\",\n    lr=1e-5,\n    optimizer_type=\"sgd\",\n    epochs=5000,\n    hidden_dim=512,\n    early_stopping=False,just_name=\"mlp\"\n)\nprint(\"MLP Classifier F1:\", best_f1)\n\n\n\"\"\"\n\nBaseline F1: 0.928632555392408\nLR=1e-4 F1: 0.9108111877521411\nAdamW F1: 0.9293011149263967\nMLP Classifier F1: 0.9399947936750244\nAdamW5000 0.9583\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda'\nmodel, preprocess = clip.load(\"ViT-L/14@336px\", device=device)  # ya da daha büyük bir model\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")\ncities = df['city'].unique().tolist()\ncity_to_idx = {c: i for i, c in enumerate(cities)}\nlabels = df['city'].apply(lambda x: city_to_idx[x]).values\nbest_model = MLPClassifier(feature_dim, hidden_dim, num_classes).to(device)\nbest_model.load_state_dict(torch.load(\"/kaggle/working/best_model_mlp.pt\"))\nbest_model.eval()\n\n\n# Test verisini yükle\ntest_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/test.csv\")  # test.csv sadece filename içeriyor\ntest_filenames = test_df['filename'].values\n\ntest_images = []\nwith torch.no_grad():\n    for fname in tqdm(test_filenames):\n        img_path = f\"/kaggle/input/datathon-ai-qualification-round/test/test/{fname}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        img_tensor = preprocess(image).unsqueeze(0).to(device)\n        \n        # CLIP modelinin encode_image fonksiyonunu kullanarak embedding çıkarıyoruz.\n        # model değişkeni CLIP modelini temsil ediyor. Eğitimi CLIP embedding'leriyle yaptığımız için testte de aynı şekilde kullanıyoruz.\n        image_features = model.encode_image(img_tensor)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        test_images.append(image_features.cpu())\n\ntest_images = torch.cat(test_images, dim=0).float().to(device)\n\nwith torch.no_grad():\n    test_outputs = best_model(test_images)\n    test_pred_idx = test_outputs.argmax(dim=1).cpu().numpy()\n    test_pred_cities = [cities[idx] for idx in test_pred_idx]\n\nsubmission_df = test_df.copy()\nsubmission_df[\"city\"] = test_pred_cities\nsubmission_df.to_csv(\"/kaggle/working/submit.csv\", index=False)\n\nprint(\"submit.csv dosyası oluşturuldu. En iyi MLP model ile test tahmini tamamlandı.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:01:16.625801Z","iopub.execute_input":"2024-12-14T18:01:16.626621Z","iopub.status.idle":"2024-12-14T18:02:41.161122Z","shell.execute_reply.started":"2024-12-14T18:01:16.626585Z","shell.execute_reply":"2024-12-14T18:02:41.160201Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/4082279870.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  best_model.load_state_dict(torch.load(\"/kaggle/working/best_model_mlp.pt\"))\n100%|██████████| 2000/2000 [01:12<00:00, 27.42it/s]","output_type":"stream"},{"name":"stdout","text":"submit.csv dosyası oluşturuldu. En iyi MLP model ile test tahmini tamamlandı.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OPENCLIP","metadata":{}},{"cell_type":"code","source":"!pip install open-clip-torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:47:20.313621Z","iopub.execute_input":"2024-12-14T11:47:20.313949Z","iopub.status.idle":"2024-12-14T11:47:30.290871Z","shell.execute_reply.started":"2024-12-14T11:47:20.313920Z","shell.execute_reply":"2024-12-14T11:47:30.290008Z"}},"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.19.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2024.5.15)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (4.66.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.26.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.4.5)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (1.0.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (2024.6.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\nDownloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy, open-clip-torch\nSuccessfully installed ftfy-6.3.1 open-clip-torch-2.29.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nimport open_clip\n\n############################\n# Data Loading and Dataset #\n############################\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\n\n###########################\n# Classifier Architectures#\n###########################\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\n###########################\n# Training/Evaluation Code#\n###########################\n\ndef extract_embeddings(model, preprocess, image_paths, labels, batch_size=32, device=\"cuda\"):\n    dataset = ImageDataset(image_paths, labels, preprocess)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    all_image_features = []\n    all_labels = []\n\n    model.eval()\n    with torch.no_grad():\n        for imgs, labs in tqdm(dataloader):\n            imgs = imgs.to(device)\n            image_features = model.encode_image(imgs)\n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n            all_image_features.append(image_features.cpu())\n            all_labels.append(labs)\n\n    all_image_features = torch.cat(all_image_features, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n    return all_image_features, all_labels\n\n\ndef train_and_evaluate(model_name,\n                       pretrained,\n                       train_df_path,\n                       train_img_dir,\n                       prompt_template=\"A photo of Türkiye in {}.\",\n                       classifier_type=\"linear\",  # \"linear\" or \"mlp\"\n                       lr=1e-3,\n                       optimizer_type=\"adam\",  # \"adam\", \"adamw\", \"sgd\"\n                       epochs=50,\n                       hidden_dim=512,\n                       weight_decay=0.0,\n                       early_stopping=False,\n                       patience=10,\n                       device=\"cuda\",\n                       just_name=\"zor\"):\n\n    # Load open_clip model\n    # For example, you can choose model_name = \"ViT-L-14\" and pretrained = \"openai\"\n    # Refer to open_clip documentation for available model/pretrained combos:\n    # https://github.com/mlfoundations/open_clip\n    model, preprocess, tokenizer = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device, quick_gelu=True) ## Quick Gelu Düzenlenecek\n    model.eval()\n\n    # Load train data\n    df = pd.read_csv(train_df_path)\n    cities = df['city'].unique().tolist()\n    city_to_idx = {c: i for i, c in enumerate(cities)}\n    labels = df['city'].apply(lambda x: city_to_idx[x]).values\n    image_paths = df['filename'].apply(lambda x: f\"{train_img_dir}/{x}\").values\n\n    # Extract embeddings\n    all_image_features, all_labels = extract_embeddings(model, preprocess, image_paths, labels, device=device)\n\n    # Split train/val\n    num_samples = len(all_image_features)\n    train_size = int(0.8 * num_samples)\n    val_size = num_samples - train_size\n\n    train_features = all_image_features[:train_size]\n    train_labels = all_labels[:train_size]\n\n    val_features = all_image_features[train_size:]\n    val_labels = all_labels[train_size:]\n\n    feature_dim = train_features.shape[1]\n    num_classes = len(cities)\n\n    # Classifier\n    if classifier_type == \"linear\":\n        classifier = LinearClassifier(feature_dim, num_classes).to(device)\n    else:\n        classifier = MLPClassifier(feature_dim, hidden_dim, num_classes).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    if optimizer_type == \"adam\":\n        opt = optim.Adam(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n    elif optimizer_type == \"adamw\":\n        opt = optim.AdamW(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n    else:  # sgd\n        opt = optim.SGD(classifier.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n\n    best_f1 = 0.0\n    no_improve_count = 0\n    model_path = f\"/kaggle/working/best_model_{just_name}.pt\"\n    \n    for epoch in range(epochs):\n        classifier.train()\n        permutation = torch.randperm(train_size)\n        train_features_shuf = train_features[permutation]\n        train_labels_shuf = train_labels[permutation]\n    \n        batch_size = 32\n        for i in range(0, train_size, batch_size):\n            batch_feats = train_features_shuf[i:i+batch_size].to(device).float()\n            batch_labs = train_labels_shuf[i:i+batch_size].to(device)\n    \n            opt.zero_grad()\n            outputs = classifier(batch_feats)\n            loss = criterion(outputs, batch_labs)\n            loss.backward()\n            opt.step()\n    \n        # Validation\n        classifier.eval()\n        with torch.no_grad():\n            val_out = classifier(val_features.float().to(device))\n            val_pred = val_out.argmax(dim=1).cpu()\n            f1 = f1_score(val_labels, val_pred, average='macro')\n    \n        if f1 > best_f1:\n            best_f1 = f1\n            no_improve_count = 0\n            torch.save(classifier.state_dict(), model_path)\n            print(f\"Best model saved with F1: {best_f1:.4f}\")\n        else:\n            no_improve_count += 1\n    \n        if early_stopping and no_improve_count >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    return best_f1, model_path, feature_dim, hidden_dim, num_classes\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###################\n# Example Run      #\n###################\n\nbest_f1, model_path, feature_dim, hidden_dim, num_classes = train_and_evaluate(\n    model_name=\"ViT-H-14-378\",\n    pretrained=\"dfn5b\",  # or another checkpoint available in open_clip\n    train_df_path=\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\",\n    train_img_dir=\"/kaggle/input/datathon-ai-qualification-round/train/train\",\n    classifier_type=\"mlp\",\n    lr=1e-3,\n    optimizer_type=\"adam\",\n    epochs=500,\n    hidden_dim=512,\n    early_stopping=False,\n    just_name=\"mlp_openclip\"\n)\n\nprint(\"MLP Classifier F1 with OpenCLIP:\", best_f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:47:49.473605Z","iopub.execute_input":"2024-12-14T11:47:49.474325Z","iopub.status.idle":"2024-12-14T12:32:40.736298Z","shell.execute_reply.started":"2024-12-14T11:47:49.474284Z","shell.execute_reply":"2024-12-14T12:32:40.735469Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"open_clip_pytorch_model.bin:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f55751ee8b04b27959d50b4fc7b24ca"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 219/219 [37:26<00:00, 10.26s/it]\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n  return F.linear(input, self.weight, self.bias)\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9364\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9500\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9522\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9530\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9560\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9572\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9580\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9586\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9607\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9615\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9615\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9622\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9622\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9629\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9629\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Best model saved with F1: 0.9643\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"MLP Classifier F1 with OpenCLIP: 0.9643219030069908\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")\ncities = df['city'].unique().tolist()\ncity_to_idx = {c: i for i, c in enumerate(cities)}\n\n# Load the best classifier\nbest_model = MLPClassifier(feature_dim, hidden_dim, num_classes).to(\"cuda\")\nbest_model.load_state_dict(torch.load(\"/kaggle/working/best_model_mlp_openclip.pt\"))\nbest_model.eval()\n\n# Load the CLIP model\nclip_model, preprocess, _ = open_clip.create_model_and_transforms(\n    \"ViT-H-14-378\", pretrained=\"dfn5b\", device=\"cuda\"\n)\nclip_model.eval()\n\n# Test Data Preparation\ntest_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/test.csv\")  # test.csv has filenames only\ntest_filenames = test_df['filename'].values\n\n# Extract embeddings for test images\ntest_images = []\nwith torch.no_grad():\n    for fname in tqdm(test_filenames):\n        img_path = f\"/kaggle/input/datathon-ai-qualification-round/test/test/{fname}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        img_tensor = preprocess(image).unsqueeze(0).to(\"cuda\")\n\n        # Use CLIP to extract image embeddings (multi-GPU compatible)\n        image_features = clip_model.module.encode_image(img_tensor)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        test_images.append(image_features.cpu())\n\n# Combine all test embeddings\ntest_images = torch.cat(test_images, dim=0).float().to(\"cuda\")\n\n# Generate predictions using the classifier\nwith torch.no_grad():\n    test_outputs = best_model(test_images)\n    test_pred_idx = test_outputs.argmax(dim=1).cpu().numpy()\n    test_pred_cities = [cities[idx] for idx in test_pred_idx]\n\n# Create and save submission file\nsubmission_df = test_df.copy()\nsubmission_df[\"city\"] = test_pred_cities\nsubmission_df.to_csv(\"/kaggle/working/submit.csv\", index=False)\n\nprint(\"submit.csv created. Predictions completed using the best MLP model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T12:55:29.068271Z","iopub.execute_input":"2024-12-14T12:55:29.068635Z","iopub.status.idle":"2024-12-14T13:06:17.457090Z","shell.execute_reply.started":"2024-12-14T12:55:29.068603Z","shell.execute_reply":"2024-12-14T13:06:17.456273Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/1539157641.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  best_model.load_state_dict(torch.load(\"/kaggle/working/best_model_mlp_openclip.pt\"))\n/opt/conda/lib/python3.10/site-packages/open_clip/factory.py:372: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n  warnings.warn(\n100%|██████████| 2000/2000 [10:34<00:00,  3.15it/s]","output_type":"stream"},{"name":"stdout","text":"submit.csv created. Predictions completed using the best MLP model.\n","output_type":"stream"},{"name":"stderr","text":"\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KFOLD OPENCLIP","metadata":{}},{"cell_type":"code","source":"!pip install open-clip-torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:24:00.578141Z","iopub.execute_input":"2024-12-14T13:24:00.578710Z","iopub.status.idle":"2024-12-14T13:24:11.073229Z","shell.execute_reply.started":"2024-12-14T13:24:00.578673Z","shell.execute_reply":"2024-12-14T13:24:11.072139Z"}},"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.19.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2024.5.15)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (4.66.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.26.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.4.5)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (1.0.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (2024.6.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\nDownloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy, open-clip-torch\nSuccessfully installed ftfy-6.3.1 open-clip-torch-2.29.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import KFold\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nimport open_clip\n\n############################\n# Data Loading and Dataset #\n############################\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\n\n###########################\n# Classifier Architectures#\n###########################\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\n###########################\n# Training/Evaluation Code#\n###########################\n\ndef extract_embeddings(model, preprocess, image_paths, labels, batch_size=32, device=\"cuda\"):\n    dataset = ImageDataset(image_paths, labels, preprocess)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    all_image_features = []\n    all_labels = []\n\n    model.eval()\n    with torch.no_grad():\n        for imgs, labs in tqdm(dataloader):\n            imgs = imgs.to(device)\n            image_features = model.encode_image(imgs)\n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n            all_image_features.append(image_features.cpu())\n            all_labels.append(labs)\n\n    all_image_features = torch.cat(all_image_features, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n    return all_image_features, all_labels\n\n\n\n\ndef train_and_evaluate_with_kfold(\n        model_name,\n        pretrained,\n        train_df_path,\n        train_img_dir,\n        prompt_template=\"A photo of Türkiye in {}.\",\n        classifier_type=\"linear\",  # \"linear\" or \"mlp\"\n        lr=1e-3,\n        optimizer_type=\"adam\",  # \"adam\", \"adamw\", \"sgd\"\n        epochs=50,\n        hidden_dim=512,\n        weight_decay=0.0,\n        early_stopping=False,\n        patience=10,\n        device=\"cuda\",\n        k_folds=5):\n\n    # Load open_clip model\n    model, preprocess, tokenizer = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device, quick_gelu=True)\n    model.eval()\n\n    # Load train data\n    df = pd.read_csv(train_df_path)\n    cities = df['city'].unique().tolist()\n    city_to_idx = {c: i for i, c in enumerate(cities)}\n    labels = df['city'].apply(lambda x: city_to_idx[x]).values\n    image_paths = df['filename'].apply(lambda x: f\"{train_img_dir}/{x}\").values\n\n    # Extract embeddings\n    all_image_features, all_labels = extract_embeddings(model, preprocess, image_paths, labels, device=device)\n\n    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n    all_f1_scores = []\n    model_paths = []\n    feature_dim = all_image_features.shape[1]\n    num_classes = len(cities)\n    fold_idx = 0\n\n    for train_idx, val_idx in kf.split(all_image_features):\n        print(f\"Fold {fold_idx + 1}/{k_folds}\")\n        fold_idx += 1\n\n        train_features = all_image_features[train_idx]\n        train_labels = all_labels[train_idx]\n        val_features = all_image_features[val_idx]\n        val_labels = all_labels[val_idx]\n\n        # Classifier\n        if classifier_type == \"linear\":\n            classifier = LinearClassifier(feature_dim, num_classes).to(device)\n        else:\n            classifier = MLPClassifier(feature_dim, hidden_dim, num_classes).to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        if optimizer_type == \"adam\":\n            opt = optim.Adam(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n        elif optimizer_type == \"adamw\":\n            opt = optim.AdamW(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n        else:  # sgd\n            opt = optim.SGD(classifier.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n\n        best_f1 = 0.0\n        no_improve_count = 0\n        model_path = f\"/kaggle/working/best_model_fold_{fold_idx}.pt\"\n\n        for epoch in range(epochs):\n            classifier.train()\n            permutation = torch.randperm(len(train_features))\n            train_features_shuf = train_features[permutation]\n            train_labels_shuf = train_labels[permutation]\n\n            batch_size = 32\n            for i in range(0, len(train_features_shuf), batch_size):\n                batch_feats = train_features_shuf[i:i + batch_size].to(device).float()\n                batch_labs = train_labels_shuf[i:i + batch_size].to(device)\n\n                opt.zero_grad()\n                outputs = classifier(batch_feats)\n                loss = criterion(outputs, batch_labs)\n                loss.backward()\n                opt.step()\n\n            # Validation\n            classifier.eval()\n            with torch.no_grad():\n                val_out = classifier(val_features.float().to(device))\n                val_pred = val_out.argmax(dim=1).cpu()\n                f1 = f1_score(val_labels, val_pred, average='macro')\n\n            if f1 > best_f1:\n                best_f1 = f1\n                no_improve_count = 0\n                torch.save(classifier.state_dict(), model_path)\n                print(f\"Best model for fold {fold_idx} saved with F1: {best_f1:.4f}\")\n            else:\n                no_improve_count += 1\n\n            if early_stopping and no_improve_count >= patience:\n                print(f\"Early stopping at epoch {epoch + 1} for fold {fold_idx}\")\n                break\n\n        all_f1_scores.append(best_f1)\n        model_paths.append(model_path)\n\n    mean_f1 = sum(all_f1_scores) / len(all_f1_scores)\n    print(f\"Mean F1 Score across {k_folds} folds: {mean_f1:.4f}\")\n\n    return all_f1_scores, mean_f1, model_paths, feature_dim, hidden_dim, num_classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:26:39.145548Z","iopub.execute_input":"2024-12-14T13:26:39.145898Z","iopub.status.idle":"2024-12-14T13:26:39.168649Z","shell.execute_reply.started":"2024-12-14T13:26:39.145866Z","shell.execute_reply":"2024-12-14T13:26:39.167789Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"###################\n# Example Run      #\n###################\n\nall_f1_scores, mean_f1, model_path, feature_dim, hidden_dim, num_classes = train_and_evaluate_with_kfold(\n    model_name=\"ViT-H-14\",\n    pretrained=\"dfn5b\",  # or another checkpoint available in open_clip\n    train_df_path=\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\",\n    train_img_dir=\"/kaggle/input/datathon-ai-qualification-round/train/train\",\n    classifier_type=\"mlp\",\n    lr=1e-3,\n    optimizer_type=\"adam\",\n    epochs=500,\n    hidden_dim=512,\n    early_stopping=False,\n)\n\nprint(\"MLP Classifier F1 with OpenCLIP:\", mean_f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:26:41.621665Z","iopub.execute_input":"2024-12-14T13:26:41.622006Z","iopub.status.idle":"2024-12-14T13:52:38.028416Z","shell.execute_reply.started":"2024-12-14T13:26:41.621975Z","shell.execute_reply":"2024-12-14T13:52:38.027504Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"open_clip_pytorch_model.bin:   0%|          | 0.00/3.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cbaae80e5a54500adc02da79865efa1"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 219/219 [13:54<00:00,  3.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/5\nBest model for fold 1 saved with F1: 0.9091\nBest model for fold 1 saved with F1: 0.9198\nBest model for fold 1 saved with F1: 0.9262\nBest model for fold 1 saved with F1: 0.9375\nBest model for fold 1 saved with F1: 0.9399\nBest model for fold 1 saved with F1: 0.9406\nBest model for fold 1 saved with F1: 0.9434\nBest model for fold 1 saved with F1: 0.9449\nBest model for fold 1 saved with F1: 0.9471\nBest model for fold 1 saved with F1: 0.9471\nBest model for fold 1 saved with F1: 0.9478\nBest model for fold 1 saved with F1: 0.9486\nBest model for fold 1 saved with F1: 0.9515\nBest model for fold 1 saved with F1: 0.9515\nBest model for fold 1 saved with F1: 0.9528\nBest model for fold 1 saved with F1: 0.9528\nBest model for fold 1 saved with F1: 0.9529\nBest model for fold 1 saved with F1: 0.9536\nBest model for fold 1 saved with F1: 0.9565\nFold 2/5\nBest model for fold 2 saved with F1: 0.9042\nBest model for fold 2 saved with F1: 0.9224\nBest model for fold 2 saved with F1: 0.9238\nBest model for fold 2 saved with F1: 0.9249\nBest model for fold 2 saved with F1: 0.9308\nBest model for fold 2 saved with F1: 0.9323\nBest model for fold 2 saved with F1: 0.9329\nBest model for fold 2 saved with F1: 0.9358\nBest model for fold 2 saved with F1: 0.9359\nBest model for fold 2 saved with F1: 0.9387\nBest model for fold 2 saved with F1: 0.9389\nBest model for fold 2 saved with F1: 0.9409\nBest model for fold 2 saved with F1: 0.9424\nBest model for fold 2 saved with F1: 0.9437\nBest model for fold 2 saved with F1: 0.9445\nBest model for fold 2 saved with F1: 0.9452\nBest model for fold 2 saved with F1: 0.9474\nBest model for fold 2 saved with F1: 0.9475\nBest model for fold 2 saved with F1: 0.9480\nBest model for fold 2 saved with F1: 0.9502\nBest model for fold 2 saved with F1: 0.9503\nFold 3/5\nBest model for fold 3 saved with F1: 0.9079\nBest model for fold 3 saved with F1: 0.9190\nBest model for fold 3 saved with F1: 0.9236\nBest model for fold 3 saved with F1: 0.9243\nBest model for fold 3 saved with F1: 0.9308\nBest model for fold 3 saved with F1: 0.9309\nBest model for fold 3 saved with F1: 0.9342\nBest model for fold 3 saved with F1: 0.9364\nBest model for fold 3 saved with F1: 0.9379\nBest model for fold 3 saved with F1: 0.9386\nBest model for fold 3 saved with F1: 0.9400\nBest model for fold 3 saved with F1: 0.9400\nBest model for fold 3 saved with F1: 0.9422\nBest model for fold 3 saved with F1: 0.9422\nBest model for fold 3 saved with F1: 0.9429\nBest model for fold 3 saved with F1: 0.9436\nBest model for fold 3 saved with F1: 0.9436\nBest model for fold 3 saved with F1: 0.9450\nBest model for fold 3 saved with F1: 0.9464\nBest model for fold 3 saved with F1: 0.9472\nBest model for fold 3 saved with F1: 0.9479\nBest model for fold 3 saved with F1: 0.9493\nBest model for fold 3 saved with F1: 0.9494\nFold 4/5\nBest model for fold 4 saved with F1: 0.8972\nBest model for fold 4 saved with F1: 0.9056\nBest model for fold 4 saved with F1: 0.9114\nBest model for fold 4 saved with F1: 0.9144\nBest model for fold 4 saved with F1: 0.9167\nBest model for fold 4 saved with F1: 0.9231\nBest model for fold 4 saved with F1: 0.9238\nBest model for fold 4 saved with F1: 0.9267\nBest model for fold 4 saved with F1: 0.9308\nBest model for fold 4 saved with F1: 0.9339\nBest model for fold 4 saved with F1: 0.9346\nBest model for fold 4 saved with F1: 0.9359\nBest model for fold 4 saved with F1: 0.9381\nBest model for fold 4 saved with F1: 0.9401\nBest model for fold 4 saved with F1: 0.9415\nBest model for fold 4 saved with F1: 0.9430\nBest model for fold 4 saved with F1: 0.9445\nBest model for fold 4 saved with F1: 0.9451\nBest model for fold 4 saved with F1: 0.9465\nBest model for fold 4 saved with F1: 0.9480\nBest model for fold 4 saved with F1: 0.9487\nBest model for fold 4 saved with F1: 0.9494\nBest model for fold 4 saved with F1: 0.9501\nBest model for fold 4 saved with F1: 0.9509\nBest model for fold 4 saved with F1: 0.9522\nBest model for fold 4 saved with F1: 0.9529\nBest model for fold 4 saved with F1: 0.9530\nBest model for fold 4 saved with F1: 0.9537\nFold 5/5\nBest model for fold 5 saved with F1: 0.9088\nBest model for fold 5 saved with F1: 0.9264\nBest model for fold 5 saved with F1: 0.9288\nBest model for fold 5 saved with F1: 0.9343\nBest model for fold 5 saved with F1: 0.9385\nBest model for fold 5 saved with F1: 0.9412\nBest model for fold 5 saved with F1: 0.9420\nBest model for fold 5 saved with F1: 0.9434\nBest model for fold 5 saved with F1: 0.9491\nBest model for fold 5 saved with F1: 0.9520\nBest model for fold 5 saved with F1: 0.9521\nBest model for fold 5 saved with F1: 0.9522\nBest model for fold 5 saved with F1: 0.9528\nBest model for fold 5 saved with F1: 0.9534\nBest model for fold 5 saved with F1: 0.9550\nMean F1 Score across 5 folds: 0.9529\nMLP Classifier F1 with OpenCLIP: 0.9529471269571823\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PROMPT + OPENCLIP + KFOLD","metadata":{}},{"cell_type":"code","source":"!pip install open-clip-torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T18:31:19.266721Z","iopub.execute_input":"2024-12-15T18:31:19.267510Z","iopub.status.idle":"2024-12-15T18:31:29.064905Z","shell.execute_reply.started":"2024-12-15T18:31:19.267446Z","shell.execute_reply":"2024-12-15T18:31:29.064126Z"}},"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.19.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2024.5.15)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (4.66.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.26.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.4.5)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (1.0.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (2024.6.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\nDownloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy, open-clip-torch\nSuccessfully installed ftfy-6.3.1 open-clip-torch-2.29.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import KFold\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nimport open_clip\nfrom torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau, OneCycleLR\nimport math\n\n############################\n# Data Loading and Dataset #\n############################\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, label\n\n\n###########################\n# Classifier Architectures#\n###########################\n\nclass LinearClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\ndef train_and_evaluate_with_kfold(\n        model_name,\n        pretrained,\n        train_df_path,\n        train_img_dir,\n        # prompt_template kullanmayacağız, onun yerine sabit prompt listesi\n        classifier_type=\"linear\",  # \"linear\" or \"mlp\"\n        lr=1e-3,\n        optimizer_type=\"adam\",  # \"adam\", \"adamw\", \"sgd\"\n        momentum=0.9,  # SGD için momentum\n        scheduler_type=None,  # \"steplr\", \"cosine\", \"plateau\", \"onecycle\"\n        step_size=10,\n        gamma=0.1,\n        epochs=50,\n        hidden_dim=256,\n        weight_decay=0.0,\n        early_stopping=False,\n        patience=10,\n        device=\"cuda\",\n        k_folds=10):\n\n    # **YENİ EKLENDİ**: Birden fazla prompt\n    prompts = [\n        \"A daytime photo of Türkiye.\",\n        \"A detailed view of a city in Türkiye.\",\n        \"An urban photograph in Türkiye.\"\n    ]\n\n    # Load open_clip model\n    model, preprocess, tokenizer = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device)\n    model.eval()\n\n    # Load train data\n    df = pd.read_csv(train_df_path)\n    cities = df['city'].unique().tolist()\n    city_to_idx = {c: i for i, c in enumerate(cities)}\n    labels = df['city'].apply(lambda x: city_to_idx[x]).values\n    image_paths = df['filename'].apply(lambda x: f\"{train_img_dir}/{x}\").values\n\n    # **YENİ EKLENDİ**: Ensemble prompt text embedding\n    with torch.no_grad():\n        text_tokens = open_clip.tokenize(prompts).to(device)\n        text_features = model.encode_text(text_tokens)\n        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n        # Ortalamasını al\n        ensemble_text_feature = text_features.mean(dim=0)  # (D,)\n\n    # Extract embeddings (sadece image)\n    def extract_embeddings(model, preprocess, image_paths, labels, device=\"cuda\"):\n        dataset = ImageDataset(image_paths, labels, preprocess)\n        dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n\n        all_image_features = []\n        all_labels = []\n\n        model.eval()\n        with torch.no_grad():\n            for imgs, labs in tqdm(dataloader):\n                imgs = imgs.to(device)\n                image_features = model.encode_image(imgs)\n                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n                all_image_features.append(image_features.cpu())\n                all_labels.append(labs)\n\n        all_image_features = torch.cat(all_image_features, dim=0)\n        all_labels = torch.cat(all_labels, dim=0)\n        return all_image_features, all_labels\n\n    all_image_features, all_labels = extract_embeddings(model, preprocess, image_paths, labels, device=device)\n\n    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n    all_f1_scores = []\n    model_paths = []\n    feature_dim = all_image_features.shape[1]\n    num_classes = len(cities)\n    fold_idx = 0\n\n    for train_idx, val_idx in kf.split(all_image_features):\n        print(f\"Fold {fold_idx + 1}/{k_folds}\")\n        fold_idx += 1\n\n        train_features = all_image_features[train_idx].to(device)\n        train_labels = all_labels[train_idx]\n        val_features = all_image_features[val_idx].to(device)\n        val_labels = all_labels[val_idx]\n\n        # Her imaj için ensemble_text_feature'ı ekle\n        text_feature_expanded_train = ensemble_text_feature.unsqueeze(0).expand(train_features.shape[0], -1)\n        text_feature_expanded_val = ensemble_text_feature.unsqueeze(0).expand(val_features.shape[0], -1)\n\n        combined_train_features = torch.cat((train_features, text_feature_expanded_train), dim=1)\n        combined_val_features = torch.cat((val_features, text_feature_expanded_val), dim=1)\n\n        combined_feature_dim = combined_train_features.shape[1]\n\n        # Classifier\n        if classifier_type == \"linear\":\n            classifier = LinearClassifier(combined_feature_dim, num_classes).to(device)\n        else:\n            classifier = MLPClassifier(combined_feature_dim, hidden_dim, num_classes).to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        if optimizer_type == \"adam\":\n            opt = optim.Adam(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n        elif optimizer_type == \"adamw\":\n            opt = optim.AdamW(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n        else:  # sgd\n            opt = optim.SGD(classifier.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n\n        # **YENİ EKLENDİ** OneCycleLR için adımlar\n        # OneCycleLR için epoch başına adım sayısını hesapla\n        batch_size = 32\n        steps_per_epoch = math.ceil(len(combined_train_features) / batch_size)\n\n        if scheduler_type == \"steplr\":\n            scheduler = StepLR(opt, step_size=step_size, gamma=gamma)\n        elif scheduler_type == \"cosine\":\n            scheduler = CosineAnnealingLR(opt, T_max=epochs)\n        elif scheduler_type == \"plateau\":\n            scheduler = ReduceLROnPlateau(opt, mode=\"max\", factor=gamma, patience=patience)\n        elif scheduler_type == \"onecycle\":\n            # OneCycleLR ile max_lr'ı belirleyin. Burada lr'nin 10 katını denedik örnek olarak.\n            scheduler = OneCycleLR(opt, max_lr=lr*10, steps_per_epoch=steps_per_epoch, epochs=epochs)\n        else:\n            scheduler = None\n\n        best_f1 = 0.0\n        no_improve_count = 0\n        model_path = f\"/kaggle/working/best_model_fold_{fold_idx}.pt\"\n\n        for epoch in range(epochs):\n            classifier.train()\n            permutation = torch.randperm(len(combined_train_features))\n            train_features_shuf = combined_train_features[permutation]\n            train_labels_shuf = train_labels[permutation]\n\n            for i in range(0, len(train_features_shuf), batch_size):\n                batch_feats = train_features_shuf[i:i + batch_size].float()\n                batch_labs = train_labels_shuf[i:i + batch_size].to(device)\n\n                opt.zero_grad()\n                outputs = classifier(batch_feats)\n                loss = criterion(outputs, batch_labs)\n                loss.backward()\n                opt.step()\n\n                # **YENİ EKLENDİ**: OneCycleLR her iterasyonda step\n                if scheduler_type == \"onecycle\":\n                    scheduler.step()\n\n            # Validation\n            classifier.eval()\n            with torch.no_grad():\n                val_out = classifier(combined_val_features.float())\n                val_pred = val_out.argmax(dim=1).cpu()\n                f1 = f1_score(val_labels, val_pred, average='macro')\n\n            # Diğer scheduler'lar epoch sonunda step alabilir\n            if scheduler is not None and scheduler_type != \"onecycle\":\n                if scheduler_type == \"plateau\":\n                    scheduler.step(f1) \n                else:\n                    scheduler.step()\n            if f1 % 50 == 0:\n                print(f\"f1: {f1} in epoch: {epoch}\")\n            if f1 > best_f1:\n                best_f1 = f1\n                no_improve_count = 0\n                torch.save(classifier.state_dict(), model_path)\n                print(f\"Best model for fold {fold_idx} saved with F1: {best_f1:.4f}\")\n            else:\n                no_improve_count += 1\n\n            if early_stopping and no_improve_count >= patience:\n                print(f\"Early stopping at epoch {epoch + 1} for fold {fold_idx}\")\n                break\n\n        all_f1_scores.append(best_f1)\n        model_paths.append(model_path)\n\n    mean_f1 = sum(all_f1_scores) / len(all_f1_scores)\n    print(f\"Mean F1 Score across {k_folds} folds: {mean_f1:.4f}\")\n\n    return all_f1_scores, mean_f1, model_paths, combined_feature_dim, hidden_dim, num_classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:37.562414Z","iopub.execute_input":"2024-12-15T16:32:37.562917Z","iopub.status.idle":"2024-12-15T16:32:38.141838Z","shell.execute_reply.started":"2024-12-15T16:32:37.562867Z","shell.execute_reply":"2024-12-15T16:32:38.140798Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"###################\n# Example Run      #\n###################\n\nMODEL_TYPE = \"ViT-H-14-378-quickgelu\"\nMODEL_PRETRAIN_DATA = \"dfn5b\"\n\n\nall_f1_scores, mean_f1, model_path, combined_feature_dim, hidden_dim, num_classes = train_and_evaluate_with_kfold(\n    model_name=MODEL_TYPE,\n    pretrained=MODEL_PRETRAIN_DATA,  # or another checkpoint available in open_clip\n    train_df_path=\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\",\n    train_img_dir=\"/kaggle/input/datathon-ai-qualification-round/train/train\",\n    classifier_type=\"mlp\",\n    lr=1e-3,\n    optimizer_type=\"sgd\",\n    epochs=100,\n    hidden_dim=1024,\n    early_stopping=False,\n    scheduler_type='plateau',\n    k_folds=5\n)\n\nprint(\"MLP Classifier F1 with OpenCLIP:\", mean_f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nimport open_clip\n\n\nMODEL_PATH = \"/kaggle/working/best_model_fold_2.pt\"\n\n# Birden fazla prompt kullanımı\nprompts = [\n    \"A daytime photo of Türkiye.\",\n    \"A detailed view of a city in Türkiye.\",\n    \"An urban photograph in Türkiye.\"\n]\n\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")\ncities = df['city'].unique().tolist()\ncity_to_idx = {c: i for i, c in enumerate(cities)}\n\n# Load the best classifier\nbest_model = MLPClassifier(combined_feature_dim, hidden_dim, num_classes).to(\"cuda\")\nbest_model.load_state_dict(torch.load(MODEL_PATH))\nbest_model.eval()\n\n# Load the CLIP model - aynı model ve checkpoint'i kullanın\nclip_model, preprocess, _ = open_clip.create_model_and_transforms(\n    MODEL_TYPE, pretrained=MODEL_PRETRAIN_DATA, device=\"cuda\")\nclip_model.eval()\n\n# Birden fazla prompt'tan ensemble text embedding elde et\nwith torch.no_grad():\n    text_tokens = open_clip.tokenize(prompts).to(\"cuda\")\n    text_features = clip_model.encode_text(text_tokens)\n    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n    # Promptların ortalamasını al\n    ensemble_text_feature = text_features.mean(dim=0)  # (D,)\n\ntest_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/test.csv\")\ntest_filenames = test_df['filename'].values\n\ntest_images = []\nwith torch.no_grad():\n    for fname in tqdm(test_filenames):\n        img_path = f\"/kaggle/input/datathon-ai-qualification-round/test/test/{fname}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        img_tensor = preprocess(image).unsqueeze(0).to(\"cuda\")\n\n        # Eğer clip_model DataParallel ile sarılı değilse .module'a gerek yoktur:\n        image_features = clip_model.encode_image(img_tensor)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        test_images.append(image_features)\n\n# Combine all test embeddings\ntest_images = torch.cat(test_images, dim=0).float().to(\"cuda\")\n\n# Her test imajına ensemble_text_feature'ı ekle\ntext_feature_expanded = ensemble_text_feature.unsqueeze(0).expand(test_images.shape[0], -1)\ntest_combined = torch.cat((test_images, text_feature_expanded), dim=1)\n\n# Generate predictions using the classifier\nwith torch.no_grad():\n    test_outputs = best_model(test_combined)\n    test_pred_idx = test_outputs.argmax(dim=1).cpu().numpy()\n    test_pred_cities = [cities[idx] for idx in test_pred_idx]\n\n# Create and save submission file\nsubmission_df = test_df.copy()\nsubmission_df[\"city\"] = test_pred_cities\nsubmission_df.to_csv(\"/kaggle/working/submit.csv\", index=False)\n\nprint(\"submit.csv created. Predictions completed using the best MLP model with ensemble text embedding.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nimport open_clip\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nquick_gelu = False\ntruncate=True # BAZI MODELLERDE TOKEN SIZE SINIRI VAR\nmodel_name = \"ViT-H-14-378-quickgelu\"\npretrained = \"dfn5b\"\nmodel, preprocess, tokenizer = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device)\nmodel.eval()\n\n# Veri Yükleme\ndf = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")\ncities = df['city'].unique().tolist()\n\n# Her şehir için birden fazla prompt tanımlayalım.\n# Örneğin, şehir ismini hafif varyasyonlarla ifade edelim. \n# Bu, modelin mükemmel bir şekilde etiketleri tahmin etmesini zorlaştırabilir.\nprompts_per_city = [\n    \"A daytime photo of {}, Türkiye.\",\n    \"A detailed urban view in {} city, Türkiye.\",\n    \"An architectural glance of {}, located in Türkiye.\"\n]\n\n# Şehir bazında ensemble text embedding oluşturma\ncity_text_features = []\nwith torch.no_grad():\n    for city in cities:\n        city_prompts = [p.format(city) for p in prompts_per_city]\n        text_tokens = open_clip.tokenize(city_prompts).to(device)\n        text_feats = model.encode_text(text_tokens)\n        text_feats = text_feats / text_feats.norm(dim=-1, keepdim=True)\n        # Ortalama alarak ensemble elde ediyoruz\n        city_feature = text_feats.mean(dim=0)  # (D,) boyutunda\n        city_text_features.append(city_feature)\n        \ncity_text_features = torch.stack(city_text_features, dim=0)  # (num_cities, D)\n\n# Zero-Shot Sınıflandırma Testi\ncorrect = 0\nfor idx, row in tqdm(df.iterrows(), total=len(df)):\n    img_path = row['filename']\n    label = row['city']\n    image_path = f\"/kaggle/input/datathon-ai-qualification-round/train/train/{img_path}\"\n    image = Image.open(image_path).convert(\"RGB\")\n    image_input = preprocess(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        image_features = model.encode_image(image_input)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n\n    # Benzerlik hesabı\n    similarity = (image_features @ city_text_features.T).squeeze(0)\n    pred_idx = similarity.argmax().item()\n    pred_city = cities[pred_idx]\n\n    if pred_city == label:\n        correct += 1\n\naccuracy = correct / len(df)\nprint(\"Zero-Shot Accuracy:\", accuracy)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PROMPT + OPENCLIP + KFOLD + AUGMENT","metadata":{}},{"cell_type":"code","source":"!pip install open-clip-torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T18:58:42.812019Z","iopub.execute_input":"2024-12-15T18:58:42.812382Z","iopub.status.idle":"2024-12-15T18:58:52.712021Z","shell.execute_reply.started":"2024-12-15T18:58:42.812310Z","shell.execute_reply":"2024-12-15T18:58:52.711206Z"}},"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.19.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2024.5.15)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (4.66.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.26.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.4.5)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (1.0.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (2024.6.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open-clip-torch) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\nDownloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy, open-clip-torch\nSuccessfully installed ftfy-6.3.1 open-clip-torch-2.29.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import KFold\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\nimport open_clip\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport math\nfrom torchvision import transforms\n\n############################\n# Data Loading and Dataset #\n############################\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n\n\n###########################\n# Classifier Architectures#\n###########################\n\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n\ndef train_and_evaluate_with_kfold(\n        model_name,\n        pretrained,\n        train_df_path,\n        train_img_dir,\n        prompts,\n        lr=1e-5,\n        optimizer_type=\"adamw\",\n        scheduler_type=\"plateau\",\n        epochs=20,\n        hidden_dim=1024,\n        weight_decay=0.01,\n        early_stopping=True,\n        patience=5,\n        device=\"cuda\",\n        k_folds=5):\n\n    # Load train data\n    df = pd.read_csv(train_df_path)\n    cities = df['city'].unique().tolist()\n    city_to_idx = {c: i for i, c in enumerate(cities)}\n    labels = df['city'].apply(lambda x: city_to_idx[x]).values\n    image_paths = df['filename'].apply(lambda x: f\"{train_img_dir}/{x}\").values\n\n    # CLIP model load\n    model, preprocess_base, tokenizer = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device)\n    model.eval()\n\n    # Prompt text features (isteğe bağlı)\n    with torch.no_grad():\n        text_tokens = open_clip.tokenize(prompts).to(device)\n        text_features = model.encode_text(text_tokens)\n        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n        ensemble_text_feature = text_features.mean(dim=0)  # (D,)\n\n    # Training augmentations (modelin beklendiği çözünürlükle uyumlu)\n    # Örneğin ViT-H-14-378 için 378x378\n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.48145466, 0.4578275, 0.40821073],\n            std=[0.26862954, 0.26130258, 0.27577711]\n        )\n    ])\n\n    val_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.48145466, 0.4578275, 0.40821073],\n            std=[0.26862954, 0.26130258, 0.27577711]\n        )\n    ])\n\n    # Öncelikle feature boyutunu bulmak için modelden bir batch geçirelim\n    # Bu sayede combined_feature_dim = image_feature_dim + text_feature_dim hesaplanır.\n    # text_features boyutu: D\n    text_dim = ensemble_text_feature.shape[0]\n\n    # Geçici olarak bir görüntü alalım\n    temp_img = Image.open(image_paths[0]).convert(\"RGB\")\n    temp_img = val_transform(temp_img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        img_feat = model.encode_image(temp_img)\n        img_feat = img_feat / img_feat.norm(dim=-1, keepdim=True)\n    image_dim = img_feat.shape[1]\n\n    combined_feature_dim = image_dim + text_dim\n    num_classes = len(cities)\n\n    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n    all_f1_scores = []\n    model_paths = []\n    fold_idx = 0\n\n    for train_idx, val_idx in kf.split(image_paths):\n        fold_idx += 1\n        print(f\"Fold {fold_idx}/{k_folds}\")\n\n        train_dataset = ImageDataset(image_paths[train_idx], labels[train_idx], transform=train_transform)\n        val_dataset = ImageDataset(image_paths[val_idx], labels[val_idx], transform=val_transform)\n\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n        # Classifier\n        classifier = MLPClassifier(combined_feature_dim, hidden_dim, num_classes).to(device)\n\n        # Unfreeze bazı katmanlar isterseniz burada yapın\n        # Örn: model parameters freeze/unfreeze\n        for param in model.parameters():\n            param.requires_grad = False\n        # Burada örnek olarak hiçbir katman açmıyoruz.\n        # Eğer fine-tune edecekseniz:\n        #num_blocks = len(model.visual.transformer.resblocks)\n        #unfreeze_blocks = 2\n        #for i in range(num_blocks - unfreeze_blocks, num_blocks):\n        #    for param in model.visual.transformer.resblocks[i].parameters():\n        #        param.requires_grad = True\n        #for param in model.visual.ln_post.parameters():\n        #    param.requires_grad = True\n\n        params_to_optimize = list(classifier.parameters())  # Fine-tune etmezsek sadece classifier optimize\n        if optimizer_type == \"adamw\":\n            opt = optim.AdamW(params_to_optimize, lr=lr, weight_decay=weight_decay)\n        else:\n            opt = optim.Adam(params_to_optimize, lr=lr, weight_decay=weight_decay)\n\n        if scheduler_type == \"plateau\":\n            scheduler = ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3)\n        else:\n            scheduler = None\n\n        best_f1 = 0.0\n        no_improve_count = 0\n        model_path = f\"/kaggle/working/best_model_fold_{fold_idx}.pt\"\n\n        for epoch in range(epochs):\n            classifier.train()\n            model.eval()  # CLIP'i freeze ettiğimiz için eval modda tutuyoruz\n            for imgs, labs in tqdm(train_loader, desc=f\"Fold {fold_idx}, Epoch {epoch+1}/{epochs} [Train]\"):\n                imgs = imgs.to(device)\n                labs = labs.to(device)\n\n                opt.zero_grad()\n                with torch.no_grad():\n                    image_features = model.encode_image(imgs)\n                    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n                # combine features\n                text_feature_expanded = ensemble_text_feature.unsqueeze(0).expand(image_features.shape[0], -1)\n                combined_features = torch.cat((image_features, text_feature_expanded), dim=1)\n                outputs = classifier(combined_features)\n                loss = nn.CrossEntropyLoss()(outputs, labs)\n                loss.backward()\n                opt.step()\n\n            # Validation\n            classifier.eval()\n            val_preds = []\n            val_trues = []\n            with torch.no_grad():\n                for imgs, labs in tqdm(val_loader, desc=f\"Fold {fold_idx}, Epoch {epoch+1}/{epochs} [Val]\"):\n                    imgs = imgs.to(device)\n                    labs = labs.to(device)\n                    image_features = model.encode_image(imgs)\n                    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n                    text_feature_expanded = ensemble_text_feature.unsqueeze(0).expand(image_features.shape[0], -1)\n                    combined_features = torch.cat((image_features, text_feature_expanded), dim=1)\n                    val_out = classifier(combined_features)\n                    val_pred = val_out.argmax(dim=1).cpu()\n                    val_preds.append(val_pred)\n                    val_trues.append(labs.cpu())\n\n            val_preds = torch.cat(val_preds)\n            val_trues = torch.cat(val_trues)\n            f1 = f1_score(val_trues, val_preds, average='macro')\n            print(f\"Fold {fold_idx}, Epoch {epoch+1}, F1: {f1:.4f}\")\n\n            if scheduler is not None:\n                scheduler.step(f1)\n\n            if f1 > best_f1:\n                best_f1 = f1\n                no_improve_count = 0\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'classifier_state_dict': classifier.state_dict()\n                }, model_path)\n                print(f\"Best model updated at Fold {fold_idx}, Epoch {epoch+1}, F1: {best_f1:.4f}\")\n            else:\n                no_improve_count += 1\n\n            if early_stopping and no_improve_count >= patience:\n                print(f\"Early stopping at epoch {epoch+1} for fold {fold_idx}\")\n                break\n\n        all_f1_scores.append(best_f1)\n        model_paths.append(model_path)\n\n    mean_f1 = sum(all_f1_scores) / len(all_f1_scores)\n    print(f\"Mean F1 Score across {k_folds} folds: {mean_f1:.4f}\")\n\n    return all_f1_scores, mean_f1, model_paths, combined_feature_dim, hidden_dim, num_classes\n\n\n###################\n# Example Run      #\n###################\n\nMODEL_TYPE = \"ViT-g-14\"\nMODEL_PRETRAIN_DATA = \"laion2b_s12b_b42k\"\n\nprompts = [\n    \"A daytime urban photograph in Türkiye.\"\n]\n\nall_f1_scores, mean_f1, model_paths, combined_feature_dim, hidden_dim, num_classes = train_and_evaluate_with_kfold(\n    model_name=MODEL_TYPE,\n    pretrained=MODEL_PRETRAIN_DATA,\n    train_df_path=\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\",\n    train_img_dir=\"/kaggle/input/datathon-ai-qualification-round/train/train\",\n    prompts=prompts,\n    lr=1e-5,\n    optimizer_type=\"adamw\",\n    epochs=10,\n    hidden_dim=128,\n    early_stopping=True,\n    patience=5,\n    scheduler_type='plateau',\n    k_folds=5\n)\n\nprint(\"Training completed.\")\nprint(\"Mean F1:\", mean_f1)\nprint(\"Model paths:\", model_paths)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aaaaaaaaaaaaaaaaa","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport pandas as pd\nimport open_clip\nfrom torchvision import transforms\n\n# Aynı classifier mimarisi\nclass MLPClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\nDEVICE = \"cuda\"\nTEST_MODEL_PATH = \"/kaggle/working/best_model_fold_2.pt\"  # Seçtiğiniz en iyi modeli belirtin\nMODEL_TYPE = \"ViT-H-14-378-quickgelu\"\nMODEL_PRETRAIN_DATA = \"dfn5b\"\n\n# Eğitimden elde ettiğiniz bu değerleri kullanın:\ncombined_feature_dim = combined_feature_dim \nhidden_dim = 1024\nnum_classes = 3  # şehir sayısı\nprompts = [\n    \"A daytime photo of Türkiye.\",\n    \"A detailed view of a city in Türkiye.\",\n    \"An urban photograph in Türkiye.\"\n]\n\ntrain_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/train_data.csv\")\ncities = train_df['city'].unique().tolist()\n\ntest_df = pd.read_csv(\"/kaggle/input/datathon-ai-qualification-round/test.csv\")\ntest_filenames = test_df['filename'].values\n\n# Modeli yükle\nmodel, preprocess_base, tokenizer = open_clip.create_model_and_transforms(\n    MODEL_TYPE, pretrained=MODEL_PRETRAIN_DATA, device=DEVICE\n)\nmodel.eval()\n\nclassifier = MLPClassifier(combined_feature_dim, hidden_dim, num_classes).to(DEVICE)\n\n# Kaydedilen model ağırlıklarını yükle\ncheckpoint = torch.load(TEST_MODEL_PATH, map_location=DEVICE)\nmodel.load_state_dict(checkpoint['model_state_dict'], strict=False)\nclassifier.load_state_dict(checkpoint['classifier_state_dict'])\nclassifier.eval()\n\n# Text embedding\nwith torch.no_grad():\n    text_tokens = open_clip.tokenize(prompts).to(DEVICE)\n    text_features = model.encode_text(text_tokens)\n    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n    ensemble_text_feature = text_features.mean(dim=0)  # (D,)\n\n# Test transform\ntest_transform = transforms.Compose([\n    transforms.Resize((378, 378)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.48145466, 0.4578275, 0.40821073],\n        std=[0.26862954, 0.26130258, 0.27577711]\n    )\n])\n\ntest_images = []\nwith torch.no_grad():\n    for fname in tqdm(test_filenames):\n        img_path = f\"/kaggle/input/datathon-ai-qualification-round/test/test/{fname}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        img_tensor = test_transform(image).unsqueeze(0).to(DEVICE)\n\n        image_features = model.encode_image(img_tensor)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        test_images.append(image_features)\n\ntest_images = torch.cat(test_images, dim=0).float().to(DEVICE)\n\n# Metin featurelarını ekle\ntext_feature_expanded = ensemble_text_feature.unsqueeze(0).expand(test_images.shape[0], -1)\ntest_combined = torch.cat((test_images, text_feature_expanded), dim=1)\n\n# Tahmin\nwith torch.no_grad():\n    test_outputs = classifier(test_combined)\n    test_pred_idx = test_outputs.argmax(dim=1).cpu().numpy()\n    test_pred_cities = [cities[idx] for idx in test_pred_idx]\n\n# Submit\nsubmission_df = test_df.copy()\nsubmission_df[\"city\"] = test_pred_cities\nsubmission_df.to_csv(\"/kaggle/working/submit.csv\", index=False)\n\nprint(\"submit.csv created. Predictions completed.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TEMIZ CLIP","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:01:39.786974Z","iopub.execute_input":"2024-12-16T02:01:39.787889Z","iopub.status.idle":"2024-12-16T02:01:53.321521Z","shell.execute_reply.started":"2024-12-16T02:01:39.787830Z","shell.execute_reply":"2024-12-16T02:01:53.320286Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-crzznkz6\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-crzznkz6\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=4bcc28c3e97b1fc5dc2bdd81f35c4e73de4f3ab667e2a833e34367b55fb68066\n  Stored in directory: /tmp/pip-ephem-wheel-cache-jpe00i8x/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport random\n\n\nimport clip\n\n#------------------------------------------------------------\n# Config\n#------------------------------------------------------------\nIMG_DIR = \"/kaggle/input/datathon-ai-qualification-round/train/train\"  # resimlerin bulunduğu klasör\nCSV_PATH = \"/kaggle/input/datathon-ai-qualification-round/train_data.csv\" # filename, city içeriyor\nNUM_FOLDS = 3\nSEED = 42\nBATCH_SIZE = 16\nEPOCHS = 10\nLR = 1e-6  # Learning rate'i biraz düşürün, artık daha fazla katman eğitiliyor.\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nCLIP_MODEL_NAME = \"ViT-B/16\"\nNUM_WORKERS = 4\nNUM_CLASSES = 3\nunfreeze_layers = 0  # Son 2 transformer bloğunu tune edelim.\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(SEED)\n\n#------------------------------------------------------------\n# Dataset\n#------------------------------------------------------------\nclass CityDataset(Dataset):\n    def __init__(self, df, img_dir, transforms=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['filename'])\n        image = self.read_image(img_path)\n        label = row['city_label']\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        return image, label\n\n    @staticmethod\n    def read_image(path):\n        import cv2\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        return img\n\n#------------------------------------------------------------\n# CLIP Normalizasyon\n#------------------------------------------------------------\nCLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\nCLIP_STD = (0.26862954, 0.26130258, 0.27577711)\n\ndef get_transforms(train=True):\n    if train:\n        return A.Compose([\n            A.RandomResizedCrop(height=224, width=224, scale=(0.8,1.0)),\n            A.HorizontalFlip(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(mean=CLIP_MEAN, std=CLIP_STD),\n            ToTensorV2(),\n        ])\n    else:\n        return A.Compose([\n            A.Resize(224,224),\n            A.Normalize(mean=CLIP_MEAN, std=CLIP_STD),\n            ToTensorV2(),\n        ])\n\n#------------------------------------------------------------\n# Model\n#------------------------------------------------------------\nclass CLIPClassifier(nn.Module):\n    def __init__(self, clip_model, num_classes):\n        super(CLIPClassifier, self).__init__()\n        self.clip_model = clip_model.float()\n        # CLIP modeli genellikle özellik boyutu ViT-B/32 için 512, ViT-L/14 için 768'dir.\n        # Aşağıda projeyi kontrol ediyoruz.\n        if hasattr(self.clip_model.visual, 'proj') and self.clip_model.visual.proj is not None:\n            embed_dim = self.clip_model.visual.proj.shape[1]\n        else:\n            # Fallback değeri\n            embed_dim = 512 \n        self.classifier = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        image_features = self.clip_model.encode_image(x)\n        logits = self.classifier(image_features)\n        return logits\n\ndef get_model(num_classes, device, unfreeze_layers=2):\n    clip_model, preprocess = clip.load(CLIP_MODEL_NAME, device=device)\n\n    # Tüm katmanları dondur\n    for param in clip_model.parameters():\n        param.requires_grad = False\n\n    # Görsel encoder: clip_model.visual\n    # Bu genellikle bir VisionTransformer. Son N bloğu açalım.\n    # clip_model.visual.transformer.resblocks: bir ModuleList 12 blok içerir (ViT-B/32 için).\n    total_blocks = len(clip_model.visual.transformer.resblocks)\n    # Son 'unfreeze_layers' bloğu aç\n    for i in range(total_blocks - unfreeze_layers, total_blocks):\n        for param in clip_model.visual.transformer.resblocks[i].parameters():\n            param.requires_grad = True\n\n    # Son olarak linear classifier serbest: \n    # Zaten classifier bizim eklediğimiz katman, varsayılan olarak requires_grad=True olacak.\n    model = CLIPClassifier(clip_model, num_classes).to(device)\n\n    # İsterseniz LayerNorm, positional embedding gibi bazı kısımları da açabilirsiniz:\n    # Örnek: \n    # for param in clip_model.visual.ln_post.parameters():\n    #     param.requires_grad = True\n    #\n    # Bu şekilde ince ayarlar yapabilirsiniz.\n\n    return model\n\n#------------------------------------------------------------\n# Eğitim/Val Fonksiyonları\n#------------------------------------------------------------\ndef train_one_epoch(model, dataloader, optimizer, scheduler, device):\n    model.train()\n    criterion = nn.CrossEntropyLoss()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if scheduler is not None:\n            scheduler.step()\n\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        total_loss += loss.item() * labels.size(0)\n\n    avg_loss = total_loss / total\n    accuracy = correct / total\n    return avg_loss, accuracy\n\ndef validate_one_epoch(model, dataloader, device):\n    model.eval()\n    criterion = nn.CrossEntropyLoss()\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            preds = outputs.argmax(dim=1)\n\n            all_preds.append(preds.cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n            \n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            total_loss += loss.item()*labels.size(0)\n\n    avg_loss = total_loss / total\n    accuracy = correct / total\n\n    from sklearn.metrics import f1_score\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    return avg_loss, accuracy, f1\n\n#------------------------------------------------------------\n# K-Fold Training\n#------------------------------------------------------------\ndf = pd.read_csv(CSV_PATH)\ncities = df['city'].unique()\ncity_to_idx = {c: i for i,c in enumerate(cities)}\ndf['city_label'] = df['city'].map(city_to_idx)\n\nX = df['filename'].values\ny = df['city_label'].values\n\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\nfold_results = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    print(f\"========== Fold {fold+1}/{NUM_FOLDS} ==========\")\n    train_df = df.iloc[train_idx].reset_index(drop=True)\n    val_df = df.iloc[val_idx].reset_index(drop=True)\n\n    train_dataset = CityDataset(train_df, IMG_DIR, transforms=get_transforms(train=True))\n    val_dataset = CityDataset(val_df, IMG_DIR, transforms=get_transforms(train=False))\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\n    model = get_model(NUM_CLASSES, DEVICE, unfreeze_layers=unfreeze_layers)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n\n    best_f1 = 0.0\n    best_model_path = f\"best_clip_model_fold{fold}.pth\"\n\n    for epoch in range(EPOCHS):\n        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scheduler, DEVICE)\n        val_loss, val_acc, val_f1 = validate_one_epoch(model, val_loader, DEVICE)\n\n        print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\")\n\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            torch.save(model.state_dict(), best_model_path)\n\n    fold_results.append(best_f1)\n\nprint(\"K-Fold Sonuçları:\")\nfor i, r in enumerate(fold_results):\n    print(f\"Fold {i+1}: F1 = {r:.4f}\")\nprint(f\"Ortalama F1 = {np.mean(fold_results):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aaaaaaaaa","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport clip\nimport torch.nn as nn\n\n# Aynı model adıyla yükleyin\nCLIP_MODEL_NAME = \"ViT-L/14\"  # Eğitimde ne kullandıysanız onu yazın\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 32\nNUM_WORKERS = 4\n\nTEST_IMG_DIR = \"/kaggle/input/datathon-ai-qualification-round/test/test\"   # Test resimlerinin olduğu klasör\nTEST_CSV_PATH = \"/kaggle/input/datathon-ai-qualification-round/test.csv\"\nMODEL_PATH = \"/kaggle/working/best_clip_model_fold1.pth\"  # Eğitilen model checkpoint'i\nTRAIN_CSV_PATH = \"/kaggle/input/datathon-ai-qualification-round/train_data.csv\" # cities bilgisini buradan alacağız\n\n# train.csv'den city bilgilerini al\ntrain_df = pd.read_csv(TRAIN_CSV_PATH)\ncities = train_df['city'].unique()\ncity_to_idx = {c: i for i,c in enumerate(cities)}\nnum_classes = len(cities)\n\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\nCLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\nCLIP_STD = (0.26862954, 0.26130258, 0.27577711)\n\ndef get_test_transforms():\n    return A.Compose([\n        A.Resize(224,224),\n        A.Normalize(mean=CLIP_MEAN, std=CLIP_STD),\n        ToTensorV2(),\n    ])\n\nclass TestDataset(Dataset):\n    def __init__(self, df, img_dir, transforms=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        filename = row['filename']\n        img_path = os.path.join(self.img_dir, filename)\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        return img, filename\n\nclass CLIPClassifier(nn.Module):\n    def __init__(self, clip_model, num_classes):\n        super(CLIPClassifier, self).__init__()\n        self.clip_model = clip_model.float()\n        # ViT-B/32 = 512 dim, ViT-L/14 = 768 dim gibi farklı olabilir\n        if hasattr(self.clip_model.visual, 'proj') and self.clip_model.visual.proj is not None:\n            embed_dim = self.clip_model.visual.proj.shape[1]\n        else:\n            # Model tipine göre ayarlayın. ViT-B/32 için genelde 512, ViT-L/14 için 768\n            embed_dim = 512\n        self.classifier = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        image_features = self.clip_model.encode_image(x)\n        logits = self.classifier(image_features)\n        return logits\n\ndef get_model(num_classes, device):\n    clip_model, _ = clip.load(CLIP_MODEL_NAME, device=device)\n    model = CLIPClassifier(clip_model, num_classes).to(device)\n    return model\n\n# Modeli oluştur\nmodel = get_model(num_classes, DEVICE)\n\n# Eğitimde kullandığınız model dosyasıyla, aynı CLIP modeli seçili mi kontrol edin.\nstate_dict = torch.load(MODEL_PATH, map_location=DEVICE)\nmodel.load_state_dict(state_dict)\n\nmodel.eval()\n\ntest_dataset = TestDataset(test_df, TEST_IMG_DIR, transforms=get_test_transforms())\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\npredictions = []\nfilenames = []\n\nwith torch.no_grad():\n    for images, fnames in test_loader:\n        images = images.to(DEVICE)\n        outputs = model(images)\n        preds = outputs.argmax(dim=1).cpu().numpy()\n        for p, f in zip(preds, fnames):\n            predictions.append(cities[p])\n            filenames.append(f)\n\nsubmission_df = test_df.copy()\nsubmission_df['city'] = predictions\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Tahminler 'submission.csv' dosyasına kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:55:01.515506Z","iopub.execute_input":"2024-12-16T00:55:01.516075Z","iopub.status.idle":"2024-12-16T00:56:08.995624Z","shell.execute_reply.started":"2024-12-16T00:55:01.516020Z","shell.execute_reply":"2024-12-16T00:56:08.994539Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2030481163.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n","output_type":"stream"},{"name":"stdout","text":"Tahminler 'submission.csv' dosyasına kaydedildi.\n","output_type":"stream"}],"execution_count":4}]}